\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Image Recognition for Enhancing Fake News Detection in the Grover Natural Language Processing Network\\
}

\author{\IEEEauthorblockN{Abdullah Kamal}
\IEEEauthorblockA{\textit{Department of Computer Science} \\
\textit{Texas State University}\\
San Marcos, TX \\
aai27@txstate.edu}
\and
\IEEEauthorblockN{Zaid Jamal}
\IEEEauthorblockA{\textit{Department of Computer Science} \\
\textit{Texas State University}\\
San Marcos, TX \\
z_j33@txstate.edu}
\and
\IEEEauthorblockN{Gabriel Rosales}
\IEEEauthorblockA{\textit{Department of Computer Science} \\
\textit{Texas State University}\\
San Marcos, TX \\
gmr94@txstate.edu}
\and
\IEEEauthorblockN{Brian Robinson}
\IEEEauthorblockA{\textit{Department of Computer Science} \\
\textit{Texas State University}\\
San Marcos, TX \\
bwr37@txstate.edu}
\and
\IEEEauthorblockN{Zachary Sotny}
\IEEEauthorblockA{\textit{Department of Computer Science} \\
\textit{Texas State University}\\
San Marcos, TX \\
zachsotny@txstate.edu}
}
\maketitle

\begin{abstract}
Fake news is a massive issue interfering with the security of factual information. On social media platforms like Twitter, Instagram, and Reddit, it is common for people to post images of news, often times falsified, to fire up their audiences or promote certain views. This being a major security concern, we decided to analyze a common fake news detection algorithm, \emph{Grover}, which is a natural language processing (NLP) \emph{neural network} that analyzes news articles to determine whether they were developer by a human or machine. After testing it on articles generated by some common Artificial Intelligence models like ChatGPT and Ryter, we noticed an inconsistency in its generation of outputs. In many cases, Grover was unable to recognize that a machine had generated the article. Additionally, in the case of social media posts, it was incapable to scan the images for text, making it impractical for usage beyond a very crude technique of manual input of an article. To counteract this flaw, we decided to utilize the Google Cloud Vision \emph{API} to analyze a data set of images pulled from various popular social media platforms to compare to actual news articles. The desired output of our project is a ground truth by which Grover can more accurate recognize an article's legitimacy. 
\end{abstract}

\begin{IEEEkeywords}
Grover, natural language processing, social media, neural network, API, image-to-text
\end{IEEEkeywords}

\section{Introduction}
Fake news is prevalent on social media, making it a major concern for people looking to find factual evidence. According to Pew Research \cite{pew2021news}, around 50\% of social media users utilize some platform to acquire the latest news. As such, we felt the need to approach this problem utilizing already accessible resources, in this case Grover, along with our own algorithm that would increase the accuracy of recognition. Grover has the ability to recognize a wide variety of fake news articles, but with social media often having information shared via images [Fig.~\ref{fig:fakenews1}], we decided on an approach other than a neural network.   

\begin{figure}
\centering
    \includegraphics[width=0.4\textwidth]{fakenews1.jpg}
    \includegraphics[width=0.4\textwidth]{fakenews2.jpg}
    \caption{Fake News Article Images From Twitter}
\label{fig:fakenews1}
\end{figure}

\section{Solution}

\subsection{Initial Approach}

In the initial stages of development, we proposed the use of a convolutional neural network (CNN) that would be trained on a completely different set of articles. Using the Soft Max activation function, we initially aimed to test the CNN on a collection of articles scraped from popular news outlets on the web and articles auto generated from ChatGPT. However, upon realizing the size of the csv's that we would need to properly train the CNN, we decided to revisit our solution. 


\subsection{Image Recognition Extension}

Our finalized approach uses image recognition and \emph{image-to-text} capabilities of the Google Cloud Vision API to analyze content published by users on various social media platforms to recognize it as real and fake news. Aiming to use our solution as an extension of the preexisting Grover model, we hope to be able to increase the scope of what Grover can analyze as well as add to the ground truth of the Grover model. By ground truth, we mean coming up with a predetermined answer to each test on Grover so there is a comparative value to work with, thus increasing the accuracy of the already trained NLP network. 

As part of our solution, we created a dynamic HTML web page to complement the image recognition software and increase the usability of our solution. While Grover is not particularly user friendly, we plan on having our open-source solution as a very easy way for people to check to see if an uploaded image on social media is factual or not. 

\section{Acknowledgements}

We would like to thank Dr. Heena Rathore for working with us to develop an implementable solution in the limited time we had prior to submission. We would also like to thank the developers of Grover for providing us with the ideas needed to produce our solution. 

\begin{thebibliography}{00}
\bibitem{pew2021news} Pew Research Center. (2021, September 20). News consumption across social media in 2021. Retrieved April 9, 2023, from \url{https://www.pewresearch.org/journalism/2021/09/20/news-consumption-across-social-media-in-2021/}
\end{thebibliography}
\vspace{12pt}

\end{document}
